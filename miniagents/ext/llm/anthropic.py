"""
This module integrates Anthropic language models with MiniAgents.
"""

import logging
import typing
from functools import cache
from pprint import pformat
from typing import Any, Optional

from miniagents.ext.llm.llm_common import message_to_llm_dict, AssistantMessage
from miniagents.messages import MessageTokenAppender
from miniagents.miniagents import miniagent, MiniAgents, InteractionContext

if typing.TYPE_CHECKING:
    import anthropic as anthropic_original

logger = logging.getLogger(__name__)


class AnthropicMessage(AssistantMessage):
    """
    A message generated by an Anthropic model.
    """


@miniagent
class anthropic_agent:  # pylint: disable=invalid-name  # TODO Oleksandr: rename to `AnthropicAgent`
    """
    An agent that represents Large Language Models by Anthropic.
    """

    def __init__(
        self,
        ctx: InteractionContext,
        model: str,
        stream: Optional[bool] = None,
        system: Optional[str] = None,
        fake_first_user_message: str = "/start",
        message_delimiter_for_same_role: str = "\n\n",
        async_client: Optional["anthropic_original.AsyncAnthropic"] = None,
        reply_metadata: Optional[dict[str, Any]] = None,
        **other_kwargs,
    ) -> None:
        self.ctx = ctx
        self.model = model
        self.stream = stream
        self.system = system
        self.fake_first_user_message = fake_first_user_message
        self.message_delimiter_for_same_role = message_delimiter_for_same_role
        self.async_client = async_client
        self.reply_metadata = reply_metadata
        self.other_kwargs = other_kwargs

        if not self.async_client:
            self.async_client = _default_anthropic_client()

        if self.stream is None:
            self.stream = MiniAgents.get_current().stream_llm_tokens_by_default

    async def __call__(self) -> None:
        """
        An agent that represents Large Language Models by Anthropic.
        """
        message_dicts = [message_to_llm_dict(msg) for msg in await self.ctx.message_promises]
        message_dicts = _fix_message_dicts(
            message_dicts,
            fake_first_user_message=self.fake_first_user_message,
            message_delimiter_for_same_role=self.message_delimiter_for_same_role,
        )

        if message_dicts and message_dicts[-1]["role"] == "system":
            # let's strip away the system message at the end (look at the implementation of `_fix_message_dicts()`
            # to see why it's there)
            system_message_dict = message_dicts.pop()
            system_combined = (
                system_message_dict["content"]
                if self.system is None
                else f"{self.system}{self.message_delimiter_for_same_role}{system_message_dict['content']}"
            )
        else:
            system_combined = self.system

        if system_combined is None:
            # pylint: disable=import-outside-toplevel
            # noinspection PyShadowingNames
            import anthropic as anthropic_original

            system_combined = anthropic_original.NOT_GIVEN

        if logger.isEnabledFor(logging.DEBUG):
            logger.debug(
                "SENDING TO ANTHROPIC:\n\n%s\nSYSTEM:\n%s\n", pformat(message_dicts), pformat(system_combined)
            )

        with MessageTokenAppender(capture_errors=True) as token_appender:
            self.ctx.reply(
                AnthropicMessage.promise(
                    start_asap=False,  # the agent is already running and will collect tokens anyway (see below)
                    message_token_streamer=token_appender,
                    # preliminary metadata:
                    model=self.model,
                    agent_alias=self.ctx.this_agent.alias,
                    **(self.reply_metadata or {}),
                )
            )
            # we already know that we there will be no more response messages, so we close the response sequence
            # (we are closing the sequence of response messages, not the sequence of message tokens)
            self.ctx.finish_early()

            if self.stream:
                async with self.async_client.messages.stream(
                    messages=message_dicts, system=system_combined, model=self.model, **self.other_kwargs
                ) as response:
                    async for token in response.text_stream:
                        token_appender.append(token)
                    anthropic_final_message = await response.get_final_message()
            else:
                anthropic_final_message = await self.async_client.messages.create(
                    messages=message_dicts, stream=False, system=system_combined, model=self.model, **self.other_kwargs
                )
                if len(anthropic_final_message.content) != 1:
                    raise RuntimeError(
                        f"exactly one TextBlock was expected from Anthropic, "
                        f"but {len(anthropic_final_message.content)} were returned instead"
                    )
                # send the complete message text as a single token
                token_appender.append(anthropic_final_message.content[0].text)

            token_appender.metadata_so_far.update(anthropic_final_message.model_dump(exclude={"content"}))


@cache
def _default_anthropic_client() -> "anthropic_original.AsyncAnthropic":
    try:
        # pylint: disable=import-outside-toplevel
        # noinspection PyShadowingNames
        import anthropic as anthropic_original
    except ModuleNotFoundError as exc:
        raise ImportError(
            "The 'anthropic' package is required for the 'anthropic' extension of MiniAgents. "
            "Please install it via 'pip install -U anthropic'."
        ) from exc

    return anthropic_original.AsyncAnthropic()


def _fix_message_dicts(
    message_dicts: list[dict[str, Any]], fake_first_user_message: str, message_delimiter_for_same_role: str
) -> list[dict[str, Any]]:
    if not message_dicts:
        return []

    # let's put all the system messages at the end (they will later be combined into a single message
    # and stripped away)
    non_system_message_dicts = [message_dict for message_dict in message_dicts if message_dict["role"] != "system"]
    system_message_dicts = [message_dict for message_dict in message_dicts if message_dict["role"] == "system"]
    message_dicts = non_system_message_dicts + system_message_dicts

    fixed_message_dicts = []
    if message_dicts[0]["role"] != "user":
        # Anthropic requires the first message to come from the user (system messages don't count -
        # their content will go into a separate, `system` parameter of the API call)
        fixed_message_dicts.append({"role": "user", "content": fake_first_user_message})

    # if multiple messages with the same role are sent in a row, they should be concatenated
    for message_dict in message_dicts:
        if fixed_message_dicts and message_dict["role"] == fixed_message_dicts[-1]["role"]:
            fixed_message_dicts[-1]["content"] += message_delimiter_for_same_role + message_dict["content"]
        else:
            fixed_message_dicts.append(message_dict)

    return fixed_message_dicts
