"""
Common classes and functions for working with large language models.
"""

import logging
from abc import ABC, abstractmethod
from pprint import pformat
from typing import Any, Optional, Type

from miniagents import InteractionContext
from miniagents.messages import Message, MessageTokenAppender
from miniagents.miniagents import MiniAgents

logger = logging.getLogger(__name__)


class UserMessage(Message):
    """
    A message from a user.
    """

    role: str = "user"


class SystemMessage(Message):
    """
    A message that is marked as a system message (a concept in large language models).
    """

    role: str = "system"


class AssistantMessage(Message):
    """
    A message generated by a large language model.
    """

    role: str = "assistant"
    model: Optional[str] = None
    agent_alias: Optional[str] = None


class LLMAgent(ABC):
    """
    A base class for agents that represents various Large Language Models.
    """

    def __init__(
        self,
        ctx: InteractionContext,
        model: str,
        stream: Optional[bool] = None,
        response_metadata: Optional[dict[str, Any]] = None,
        response_message_class: Type[Message] = AssistantMessage,
    ) -> None:
        self.ctx = ctx
        self.model = model
        self.stream = stream
        self.response_metadata = response_metadata
        self._response_message_class = response_message_class

        if self.stream is None:
            self.stream = MiniAgents.get_current().stream_llm_tokens_by_default

    async def __call__(self) -> None:
        message_dicts = await self._prepare_message_dicts()

        if logger.isEnabledFor(logging.DEBUG):
            logger.debug("SENDING TO LLM:\n\n%s\n", pformat(message_dicts))

        with MessageTokenAppender(capture_errors=True) as token_appender:
            await self._promise_and_close(token_appender, self._response_message_class)
            await self._produce_tokens(message_dicts, token_appender)

    @abstractmethod
    async def _prepare_message_dicts(self) -> list[dict[str, Any]]:
        """
        TODO Oleksandr: docstring
        """

    @abstractmethod
    async def _produce_tokens(self, message_dicts: list[dict[str, Any]], token_appender: MessageTokenAppender) -> None:
        """
        TODO Oleksandr: docstring
        """

    async def _promise_and_close(self, token_appender: MessageTokenAppender, message_class: Type[Message]) -> None:
        """
        TODO Oleksandr: docstring
        """
        self.ctx.reply(
            message_class.promise(
                start_asap=False,  # the agent is already running and will collect tokens anyway (see below)
                message_token_streamer=token_appender,
                # preliminary metadata:
                model=self.model,
                agent_alias=self.ctx.this_agent.alias,
                **(self.response_metadata or {}),
            )
        )
        # we already know that there will be no more response messages, so we close the response sequence
        # (we are closing the sequence of response messages, not the sequence of message tokens)
        await self.ctx.afinish_early()

    @staticmethod
    def _message_to_llm_dict(message: Message) -> dict[str, Any]:
        """
        Convert a message to a dictionary that can be sent to a large language model.
        """
        try:
            role = message.role
        except AttributeError:
            role = "user"

        return {
            "role": role,
            "content": str(message),
        }
