"""
Common classes and functions for working with large language models.
"""

from abc import ABC, abstractmethod
from typing import Any, Optional, Type

from miniagents.messages import Message, MessageTokenAppender, MessagePromise
from miniagents.miniagents import InteractionContext, MiniAgents, MiniAgent


class UserMessage(Message):
    """
    A message from a user.
    """

    role: str = "user"


class SystemMessage(Message):
    """
    A message that is marked as a system message (a concept in large language models).
    """

    role: str = "system"


class AssistantMessage(Message):
    """
    A message generated by a large language model.
    """

    role: str = "assistant"
    model: Optional[str] = None
    agent_alias: Optional[str] = None


class LLMAgent(ABC):
    """
    A base class for agents that represents various Large Language Models.
    """

    def __init__(
        self,
        ctx: InteractionContext,
        model: str,
        stream: Optional[bool] = None,
        response_metadata: Optional[dict[str, Any]] = None,
        response_message_class: Type[Message] = AssistantMessage,
        llm_logger_agent: Optional[MiniAgent] = None,
    ) -> None:
        self.ctx = ctx
        self.model = model
        self.stream = stream
        self.response_metadata = response_metadata
        self.response_message_class = response_message_class
        self.llm_logger_agent = llm_logger_agent

        if self.stream is None:
            self.stream = MiniAgents.get_current().stream_llm_tokens_by_default

    async def __call__(self) -> None:
        message_dicts = await self._prepare_message_dicts()

        with MessageTokenAppender(capture_errors=True) as token_appender:
            response_promise = await self._promise_and_close(token_appender)
            if self.llm_logger_agent:
                self.llm_logger_agent.kick_off([message_dicts, response_promise])
            await self._produce_tokens(message_dicts, token_appender)

    @abstractmethod
    async def _prepare_message_dicts(self) -> list[dict[str, Any]]:
        """
        TODO Oleksandr: docstring
        """

    @abstractmethod
    async def _produce_tokens(self, message_dicts: list[dict[str, Any]], token_appender: MessageTokenAppender) -> None:
        """
        TODO Oleksandr: docstring
        """

    async def _promise_and_close(self, token_appender: MessageTokenAppender) -> MessagePromise:
        """
        TODO Oleksandr: docstring
        """
        response_promise = self.response_message_class.promise(
            start_asap=False,  # the agent is already running and will collect tokens anyway (see below)
            message_token_streamer=token_appender,
            # preliminary metadata:
            model=self.model,
            agent_alias=self.ctx.this_agent.alias,
            **(self.response_metadata or {}),
        )
        self.ctx.reply(response_promise)
        # we already know that there will be no more response messages, so we close the response sequence
        # (we are closing the sequence of response messages, not the sequence of message tokens)
        await self.ctx.afinish_early()

        return response_promise

    @staticmethod
    def _message_to_llm_dict(message: Message) -> dict[str, Any]:
        """
        Convert a message to a dictionary that can be sent to a large language model.
        """
        try:
            role = message.role
        except AttributeError:
            role = "user"

        return {
            "role": role,
            "content": str(message),
        }
