"""
Common classes and functions for working with large language models.
"""

from abc import ABC, abstractmethod
from typing import Any, Optional

from pydantic import ConfigDict, Field, BaseModel

from miniagents.messages import Message, MessageTokenAppender, MessagePromise
from miniagents.miniagents import InteractionContext, MiniAgents, MiniAgent


class UserMessage(Message):
    """
    A message from a user.
    """

    role: str = "user"


class SystemMessage(Message):
    """
    A message that is marked as a system message (a concept in large language models).
    """

    role: str = "system"


class AssistantMessage(Message):
    """
    A message generated by a large language model.
    """

    role: str = "assistant"
    model: Optional[str] = None
    agent_alias: Optional[str] = None


class LLMAgent(ABC, BaseModel):
    """
    A base class for agents that represents various Large Language Models.
    """

    model_config = ConfigDict(arbitrary_types_allowed=True, extra="allow")

    ctx: InteractionContext
    model: str
    stream: bool = Field(default_factory=lambda: MiniAgents.get_current().stream_llm_tokens_by_default)
    system: Optional[str] = None
    response_metadata: Optional[dict[str, Any]] = None
    response_message_class: type[Message] = AssistantMessage
    llm_logger_agent: Optional[MiniAgent] = None

    async def __call__(self) -> None:
        message_dicts = await self._prepare_message_dicts()

        with MessageTokenAppender(capture_errors=True) as token_appender:
            response_promise = await self._promise_and_close(token_appender)

            if self.llm_logger_agent:
                self.llm_logger_agent.kick_off(
                    [
                        message_dicts,
                        response_promise,
                    ],
                    metadata={
                        "agent_alias": self.ctx.this_agent.alias,
                        "model": self.model,
                        "stream": self.stream,
                        "system": self.system,
                        **self.__pydantic_extra__,
                    },
                )
            await self._produce_tokens(message_dicts, token_appender)

    @abstractmethod
    async def _prepare_message_dicts(self) -> list[dict[str, Any]]:
        """
        TODO Oleksandr: docstring
        """

    @abstractmethod
    async def _produce_tokens(self, message_dicts: list[dict[str, Any]], token_appender: MessageTokenAppender) -> None:
        """
        TODO Oleksandr: docstring
        """

    async def _promise_and_close(self, token_appender: MessageTokenAppender) -> MessagePromise:
        """
        TODO Oleksandr: docstring
        """
        response_promise = self.response_message_class.promise(
            start_asap=False,  # the agent is already running and will collect tokens anyway (see below)
            message_token_streamer=token_appender,
            # preliminary metadata:
            model=self.model,
            agent_alias=self.ctx.this_agent.alias,
            **(self.response_metadata or {}),
        )
        self.ctx.reply(response_promise)
        # we already know that there will be no more response messages, so we close the response sequence
        # (we are closing the sequence of response messages, not the sequence of message tokens)
        await self.ctx.afinish_early()

        return response_promise

    @staticmethod
    def _message_to_llm_dict(message: Message) -> dict[str, Any]:
        """
        Convert a message to a dictionary that can be sent to a large language model.
        """
        try:
            role = message.role
        except AttributeError:
            role = "user"

        return {
            "role": role,
            "content": str(message),
        }
