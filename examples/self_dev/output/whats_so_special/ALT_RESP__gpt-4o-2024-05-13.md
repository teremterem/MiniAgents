MiniAgents distinguishes itself from other frameworks like LangChain, LangGraph,
Llama-Index, and Haystack-ai through several unique features and design
philosophies:

1. **Asynchronous Token Streaming**:
    - **Core Feature**: MiniAgents is built around supporting asynchronous token
      streaming across chains of interconnected agents. This is a core feature
      of the framework, allowing for real-time, token-by-token processing and
      interaction.
    - **Granular Control**: You can read agent responses token-by-token,
      regardless of whether the agent is streaming token by token or returning
      full messages. This allows for more granular control over the interaction
      process.

2. **Immutable, Pydantic-based Messages**:
    - **Immutability**: Messages in MiniAgents are immutable once created. This
      ensures that the state of a message cannot be changed in the background,
      providing consistency and reliability.
    - **Pydantic Integration**: The framework leverages Pydantic for data
      validation and serialization, ensuring that messages are well-defined and
      adhere to specified schemas.

3. **Hierarchical Message Resolution**:
    - **Flexible Message Handling**: MiniAgents allows for throwing bare
      strings, messages, message promises, collections, and sequences of
      messages and message promises into an agent reply. This hierarchical
      structure is asynchronously resolved into a flat and uniform sequence of
      message promises.
    - **Automatic Flattening**: The framework automatically "flattens" nested
      message structures, making it easier to work with complex interactions.

4. **Start-asap Mode**:
    - **Background Processing**: By default, agents in MiniAgents work in
      a `start_asap` mode, which means they actively seek every opportunity to
      proceed with their processing in the background when async tasks switch.
      This is different from the usual way coroutines work, where you need to
      actively await them.
    - **Replayable Promises**: The framework uses streamed promises that are "
      replayable" by nature, allowing for multiple consumers to iterate over the
      stream independently.

5. **Agent Parallelism**:
    - **Parallel Execution**: MiniAgents supports parallel execution of agents,
      allowing for more efficient and concurrent processing of tasks.
    - **Agent Aggregation**: The framework provides built-in support for
      aggregating agents into chains, loops, and dialogs, enabling complex
      multi-agent interactions.

6. **Built-in LLM Integrations**:
    - **OpenAI and Anthropic**: MiniAgents provides built-in support for OpenAI
      and Anthropic language models, with the possibility to add other
      integrations.
    - **Token and Message Streaming**: The framework is designed to handle both
      token and message streaming seamlessly, making it suitable for real-time
      applications.

7. **Message Persistence and Identification**:
    - **Persistence Hooks**: MiniAgents provides a way to persist messages as
      they are resolved from promises using
      the `@MiniAgents().on_persist_message` decorator. This allows for custom
      logic for storing or logging messages.
    - **Hash-based Identification**: Messages have a `hash_key` property that
      calculates the SHA-256 hash of the content of the message, providing a
      unique identifier for each message.

8. **Ease of Use**:
    - **Simple API**: The framework offers a simple and intuitive API for
      defining and interacting with agents.
    - **Context Management**: MiniAgents provides a context manager for managing
      the lifecycle of agents and promises, ensuring that all async tasks are
      properly handled.

9. **Focus on Multi-Agent Systems**:
    - **Multi-Agent Interactions**: The framework is specifically designed for
      building LLM-based multi-agent systems, making it a specialized tool for
      scenarios where multiple agents need to interact and collaborate.

In summary, MiniAgents sets itself apart by focusing on asynchronous token
streaming, immutable messages, hierarchical message resolution, start-asap mode,
agent parallelism, built-in LLM integrations, message persistence, and ease of
use. These features make it a powerful and flexible framework for building
complex, real-time, multi-agent systems.
