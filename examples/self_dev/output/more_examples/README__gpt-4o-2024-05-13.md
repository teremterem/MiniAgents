# MiniAgents

⚠️ ATTENTION! THIS README IS WORK IN PROGRESS (autogenerated with `Claude 3 Opus` and `GPT 4o` and not corrected yet) ⚠️

---

## Why does this framework exist at all? What is the problem it solves? What is the motivation behind it?

MiniAgents is a Python framework designed to facilitate the creation and management of agents that interact with language models (LLMs) and other services. It provides a structured way to define, call, and manage agents, making it easier to build complex systems that rely on asynchronous interactions and streaming data.

## Features

- **Agent Management**: Easily create, manage, and chain multiple agents using simple decorators.
- **Chat History**: Manage chat history with support for in-memory and markdown file storage.
- **Asynchronous Interaction**: Support for asynchronous interactions with agents.
- **Streaming**: Stream data token by token or message by message.
- **LLM Integration**: Seamlessly integrate with popular LLMs like OpenAI and Anthropic.
- **Message Handling**: Robust message handling with support for nested messages and promises.
- **Utilities**: A set of utility functions to facilitate common tasks like dialog loops and message joining.
- **Immutable Messages**: Ensures that messages are immutable, making the system more predictable and easier to debug.

## Installation

```bash
pip install miniagents
```

## Usage

### Basic Example

Here's a simple example of how to define an agent:

```python
from miniagents import miniagent, InteractionContext

@miniagent
async def my_agent(ctx: InteractionContext):
    async for message in ctx.message_promises:
        ctx.reply(f"You said: {message}")
```

And here's how to initiate an interaction with the agent:

```python
from miniagents import MiniAgents

async with MiniAgents():
    reply = await my_agent.inquire("Hello!")
    print(reply)  # prints "You said: Hello!"
```

### Advanced Example

For more advanced usage, you can define multiple agents and manage their interactions:

```python
from miniagents import miniagent, MiniAgents, InteractionContext
from miniagents.promising.sentinels import AWAIT
from miniagents.utils import achain_loop

@miniagent
async def user_agent(ctx: InteractionContext) -> None:
    async for msg_promise in ctx.message_promises:
        async for token in msg_promise:
            print(token, end="", flush=True)
        print()
    ctx.reply(input("USER: "))

@miniagent
async def assistant_agent(ctx: InteractionContext) -> None:
    async for msg_promise in ctx.message_promises:
        async for token in msg_promise:
            print(token, end="", flush=True)
        print()
    ctx.reply("Hello, how can I assist you?")

async def amain() -> None:
    await achain_loop([user_agent, AWAIT, assistant_agent])

if __name__ == "__main__":
    MiniAgents().run(amain())
```

### Integrating with LLMs

MiniAgents provides built-in support for OpenAI and Anthropic language models. You can create agents for these models using the provided functions.

#### OpenAI Integration

```python
from miniagents.ext.llm.openai import openai_agent
from miniagents.messages import Message

openai_agent = openai_agent.fork(model="gpt-3.5-turbo")

async def main():
    async with MiniAgents():
        replies = openai_agent.inquire(
            Message(text="Hello, how are you?", role="user"),
            system="You are a helpful assistant.",
            max_tokens=50,
            temperature=0.7,
        )
        async for reply in replies:
            print(await reply)

import asyncio

asyncio.run(main())
```

#### Anthropic Integration

```python
from miniagents.ext.llm.anthropic import anthropic_agent

anthropic_agent = anthropic_agent.fork(model="claude-3-haiku-20240307")

async def main():
    async with MiniAgents():
        replies = anthropic_agent.inquire(
            Message(text="Hello, how are you?", role="user"),
            system="You are a helpful assistant.",
            max_tokens=50,
            temperature=0.7,
        )
        async for reply in replies:
            print(await reply)

import asyncio

asyncio.run(main())
```

### Error Handling and Exceptions

MiniAgents treats exceptions in agents as messages, allowing for graceful error handling and recovery in multi-agent systems.

```python
from miniagents.miniagents import miniagent, MiniAgents, InteractionContext

@miniagent
async def error_handling_agent(ctx: InteractionContext):
    try:
        async for message in ctx.message_promises:
            if message.text == "error":
                raise ValueError("An error occurred")
            ctx.reply(f"Received: {message.text}")
    except ValueError as e:
        ctx.reply(f"Error: {str(e)}")

async def main():
    async with MiniAgents():
        reply = await error_handling_agent.inquire("error")
        print(await reply)

import asyncio

asyncio.run(main())
```

### Custom Message Types

You can create custom message types by subclassing `Message`.

```python
from miniagents.messages import Message

class CustomMessage(Message):
    custom_field: str

message = CustomMessage(text="Hello", custom_field="Custom Value")
print(message.text)  # Output: Hello
print(message.custom_field)  # Output: Custom Value
```

### Persisting Chat History

MiniAgents provides built-in support for chat history management, including in-memory and Markdown-based persistence options.

```python
from miniagents.ext.history_agents import markdown_history_agent
from miniagents.ext.llm.openai import openai_agent
from miniagents.miniagents import MiniAgents
from miniagents.utils import adialog_loop

async def main():
    async with MiniAgents():
        await adialog_loop(
            user_agent=console_user_agent,
            assistant_agent=openai_agent.fork(model="gpt-3.5-turbo"),
            history_agent=markdown_history_agent.fork(history_md_file="chat_history.md")
        )

import asyncio

asyncio.run(main())
```

### Utility Functions

MiniAgents provides several utility functions to help with common tasks:

- **join_messages**: Join multiple messages into a single message.
- **split_messages**: Split a message into multiple messages based on a delimiter.

#### Joining Messages

```python
from miniagents.utils import join_messages

async def main():
    async with MiniAgents() as context:
        joined_message = join_messages(["Hello", "World"], delimiter=" ")
        print(await joined_message.aresolve())

MiniAgents().run(main())
```

#### Splitting Messages

```python
from miniagents.utils import split_messages

async def main():
    message = "Hello\n\nworld"
    split_message = split_messages(message)
    print(await split_message)

MiniAgents().run(main())
```

### Self-Development Features

MiniAgents includes self-development capabilities, allowing agents to improve their own behavior over time.

```python
from examples.self_dev.readme_agent import readme_agent
from miniagents.miniagents import MiniAgents

async def main():
    async with MiniAgents():
        await readme_agent.inquire()

import asyncio

asyncio.run(main())
```

## Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details.

## License

MiniAgents is released under the [MIT License](LICENSE).

## FAQ

1. **Q: How does MiniAgents differ from other agent frameworks?**
   A: MiniAgents focuses on asynchronous execution, immutable message passing, and easy integration with LLMs. It's designed for building complex, streaming-capable multi-agent systems.

2. **Q: Can I use MiniAgents with LLM providers other than OpenAI and Anthropic?**
   A: Yes, the framework is extensible. You can create custom agents for other LLM providers by following the patterns in the existing implementations.

3. **Q: How does MiniAgents handle errors in agents?**
   A: Exceptions in agents are treated as messages, allowing for graceful error handling and recovery in multi-agent systems.

4. **Q: Is MiniAgents suitable for production use?**
   A: While MiniAgents is being actively developed, it's designed with production use cases in mind. However, always thoroughly test and evaluate it for your specific needs.

5. **Q: How can I persist agent interactions?**
   A: MiniAgents provides built-in support for chat history management, including in-memory and Markdown-based persistence options.

## Things to remember (for the developers of this framework)

- **Different Promise and StreamedPromise resolvers, piece streamers, appenders and what not should always catch BaseExceptions and not just Exceptions** when they capture errors to pass those errors as "pieces" in order for those errors to be raised at the "consumer side". This is because many of the aforementioned Promising "primitives" are often part of mechanisms that involve communications between async tasks via asyncio.Queue objects and just interrupting those promises with KeyboardInterrupt which are extended from BaseException instead of letting KeyboardInterrupt to go through the queue leads to hanging of those promises (a queue is waiting for END_OF_QUEUE sentinel forever but the task that should send it is dead).

---

This README provides an overview of the MiniAgents framework, its features, installation instructions, usage examples, and information on testing and contributing. For more detailed documentation, please refer to the source code and comments within the project.

---

Happy coding with MiniAgents! 🚀
