# MiniAgents

⚠️ ATTENTION! THIS README IS WORK IN PROGRESS (autogenerated with `Claude 3 Opus` and `GPT 4o` and not corrected yet) ⚠️

---

MiniAgents is a Python framework for building agent-based systems. It provides a simple and intuitive way to define agents and their interactions.

MiniAgents is a Python framework designed to facilitate the creation and management of agents that interact with language models (LLMs) and other services. It provides a structured way to define, call, and manage agents, making it easier to build complex systems that rely on asynchronous interactions and streaming data.

An asynchronous framework for building LLM-based multi-agent systems in Python, with a focus on immutable messages and token streaming.

## Features

- **Agent Management**: Define and manage agents using simple decorators.
- **Chat History**: Flexible chat history management, including in-memory and Markdown-based persistence
- **Asynchronous Interaction**: Support for asynchronous interactions with agents.
- **Streaming**: Stream data token by token or message by message.
- **LLM Integration**: Seamlessly integrate with popular LLMs like OpenAI and Anthropic.
- **Message Handling**: Robust message handling with support for nested messages and promises.
- **Utilities**: A set of utility functions to facilitate common tasks like dialog loops and message joining.
- **Immutable Messages**: Ensures that messages are immutable, making the system more predictable and easier to debug.

## Installation

```bash
pip install miniagents
```

## Usage

Here's a simple example of how to define an agent:

```python
from miniagents import miniagent, InteractionContext


@miniagent
async def my_agent(ctx: InteractionContext):
    async for message in ctx.message_promises:
        ctx.reply(f"You said: {message}")
```

And here's how to initiate an interaction with the agent:

```python
from miniagents import MiniAgents

async with MiniAgents():
    reply = await my_agent.inquire("Hello!")
    print(reply)  # prints "You said: Hello!"
```

For more advanced usage, check out the [examples](examples/) directory.

## Examples and Use Cases

### Advanced Agent Interaction with Custom Messages

You can create custom message types by subclassing `Message` and have agents interact using these custom messages:

```python
from miniagents.messages import Message
from miniagents.miniagents import miniagent, MiniAgents, InteractionContext

class CustomMessage(Message):
    custom_field: str

@miniagent
async def custom_agent(ctx: InteractionContext):
    async for message in ctx.message_promises:
        if isinstance(message, CustomMessage):
            ctx.reply(f"Received custom message with field: {message.custom_field}")
        else:
            ctx.reply("Received a standard message")

async def main():
    async with MiniAgents():
        reply = await custom_agent.inquire(CustomMessage(text="Hello", custom_field="Custom Value"))
        print(await reply)

asyncio.run(main())
```

### Persisting Chat History to Markdown

You can use the `markdown_history_agent` to persist chat history to a Markdown file:

```python
from miniagents.ext.history_agents import markdown_history_agent
from miniagents.ext.misc_agents import console_user_agent
from miniagents.ext.llm.openai import openai_agent
from miniagents.miniagents import MiniAgents
from miniagents.utils import adialog_loop

async def main() -> None:
    async with MiniAgents():
        await adialog_loop(
            user_agent=console_user_agent.fork(chat_history=ChatHistoryMD("CHAT.md")),
            assistant_agent=openai_agent.fork(model="gpt-4o-2024-05-13"),
        )

asyncio.run(main())
```

### Using `StreamedPromise` for Token Streaming

You can use `StreamedPromise` to handle token streaming from an LLM:

```python
from miniagents.ext.llm.openai import openai_agent
from miniagents.miniagents import MiniAgents

async def main() -> None:
    async with MiniAgents():
        reply_sequence = openai_agent.inquire("Stream this response", stream=True)
        async for msg_promise in reply_sequence:
            async for token in msg_promise:
                print(token, end="", flush=True)
            print()

asyncio.run(main())
```

### Handling Errors in Agents

You can handle errors in agents and treat them as messages:

```python
from miniagents.miniagents import miniagent, MiniAgents, InteractionContext

@miniagent
async def error_handling_agent(ctx: InteractionContext):
    try:
        async for message in ctx.message_promises:
            if message.text == "error":
                raise ValueError("An error occurred")
            ctx.reply(f"Received: {message.text}")
    except ValueError as e:
        ctx.reply(f"Error: {str(e)}")

async def main():
    async with MiniAgents():
        reply = await error_handling_agent.inquire("error")
        print(await reply)

asyncio.run(main())
```

### Using `achain_loop` for Chaining Multiple Agents

You can use `achain_loop` to chain multiple agents together:

```python
from miniagents.miniagents import miniagent, MiniAgents, InteractionContext
from miniagents.utils import achain_loop

@miniagent
async def agent1(ctx: InteractionContext):
    ctx.reply("Message from Agent 1")

@miniagent
async def agent2(ctx: InteractionContext):
    ctx.reply("Message from Agent 2")

async def main():
    async with MiniAgents():
        await achain_loop([agent1, agent2])

asyncio.run(main())
```

### Custom Chat History Handler

You can create a custom chat history handler by extending the `ChatHistory` class:

```python
from miniagents.ext.history_agents import ChatHistory
from miniagents.miniagents import miniagent, MiniAgents, InteractionContext

class CustomChatHistory(ChatHistory):
    def __init__(self):
        self.history = []

    async def add_message(self, message):
        self.history.append(message)

    async def get_history(self):
        return self.history

@miniagent
async def custom_history_agent(ctx: InteractionContext):
    history = CustomChatHistory()
    async for message in ctx.message_promises:
        await history.add_message(message)
        ctx.reply(f"History: {await history.get_history()}")

async def main():
    async with MiniAgents():
        reply = await custom_history_agent.inquire("Hello")
        print(await reply)

asyncio.run(main())
```

## Documentation

### Modules

- `miniagents`: Core classes and functions.
- `miniagents.ext`: Extensions for integrating with external services and libraries.
- `miniagents.promising`: Classes and functions for handling promises and asynchronous operations.
- `miniagents.utils`: Utility functions for common tasks.

### Core Concepts

- **MiniAgents**: The main context manager that handles the lifecycle of agents and their interactions.
- **MiniAgent**: A wrapper for an agent function that allows calling the agent.
- **InteractionContext**: Provides context for the interaction, including the messages and the agent.
- **Message**: Represents a message that can be sent between agents.
- **MessagePromise**: A promise of a message that can be streamed token by token.
- **MessageSequencePromise**: A promise of a sequence of messages that can be streamed message by message.

### Extending MiniAgents

You can extend the functionality of MiniAgents by creating custom agents, message types, and chat history handlers. The framework is designed to be modular and flexible, allowing you to integrate it with various services and customize its behavior to fit your needs.

## Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details.

## License

MiniAgents is released under the [MIT License](LICENSE).
